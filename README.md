


## Desafio - Desenvolver 2 web crawlers pra extração de dados | Node.js - Puppeteer


#### Web crawler é um programa de computador que navega pela rede de uma forma metódica e automatizada, basicamente funciona como uma forma de extrair informações de diversas páginas. 


## Requisitos do desafio:

- Realizar todo o fluxo para chegar até a informação (crawler em si)
- O crawler NÃO PODERÁ ser feito utilizando Selenium, é necessário utilizar a API
Requests do Puppeteer.
- Realizar o parser para obter o resultado esperado em anexo
- Desenvolvimento de teste de integração (crawler rodar como um todo)
- Publicar todo o trabalho no Github
- Criar um README.md
- O formato do JSON é obrigatório, ou seja, deverá ser seguido a risca o nome dos campos
e o tipo de dados em cada um.

### Ferramentas Utilizadas
- Desenvolvimento:
  - nodeJS
  - express
  - puppeteer
  - request

- Testes:
  - jest
  - supertest

### Como baixar o projeto?

- Faça um clone desse repositório;
- Acesse o arquivo local que deseja instalar através do terminal da sua máquina e digite: 
```sh
git clone https://github.com/ManuelMolina02/webcrawling-puppeteer.git
```
Após baixar o projeto, ainda no terminal execute os comandos:

Para instalar:
```sh
npm install
```

Iniciar o projeto:
```sh
npm start
```

Realizar o testes de validação:
```sh
npm test
```
